# listeners/messages/message_im.py
from logging import Logger
from slack_bolt import App, Say
from slack_sdk import WebClient
import time

from ai.providers.letta_stream import LettaAPIStreaming
from ..listener_utils.listener_constants import DEFAULT_LOADING_TEXT
from ..listener_utils.parse_conversation import parse_conversation

# Throttle updates to avoid Slack rate limits
THROTTLE_SECONDS = 0.5          # minimum time between edits
MAX_MESSAGE_LEN = 39000         # stay below Slack hard limits
BATCH_CHUNKS = 5                # also edit every N chunks (in addition to time)


def _handle_dm(event: dict, client: WebClient, logger: Logger, say: Say):
    # Only handle plain DM messages (ignore subtypes/bot messages)
    if event.get("channel_type") != "im" or event.get("subtype"):
        return

    channel_id = event.get("channel")
    user_id = event.get("user")
    text = (event.get("text") or "").strip()

    # 1) Fetch brief DM context to help the agent stay on-topic
    try:
        history = client.conversations_history(channel=channel_id, limit=10)["messages"]
    except Exception as e:
        logger.exception("Failed to fetch DM context: %s", e)
        history = []

    conversation_context = parse_conversation(history[:-1]) if history else ""

    # 2) Post a placeholder we'll update as we stream
    waiting = say(text=DEFAULT_LOADING_TEXT)

    # 3) Build prompts
    system = "You are a helpful Slack bot. Be concise and helpful."
    user_prompt = (
        (f"DM so far:\n{conversation_context}\n\n") if conversation_context else ""
    ) + f"User <@{user_id}> says:\n{text or 'Hello'}"

    # 4) Stream from Letta and progressively update the Slack message
    streamer = LettaAPIStreaming()
    chunks = []
    last_edit = 0.0

    try:
        for i, delta in enumerate(streamer.chat_stream(system, user_prompt), start=1):
            if not isinstance(delta, str):
                delta = str(delta)
            chunks.append(delta)

            now = time.time()
            if (now - last_edit) >= THROTTLE_SECONDS or (i % BATCH_CHUNKS) == 0:
                partial = "".join(chunks)
                if len(partial) > MAX_MESSAGE_LEN:
                    partial = partial[:MAX_MESSAGE_LEN] + "…"
                client.chat_update(channel=channel_id, ts=waiting["ts"], text=partial)
                last_edit = now

        # Final update
        final_text = "".join(chunks).strip() or "(no content)"
        if len(final_text) > MAX_MESSAGE_LEN:
            final_text = final_text[:MAX_MESSAGE_LEN] + "…"
        client.chat_update(channel=channel_id, ts=waiting["ts"], text=final_text)

    except Exception as e:
        logger.exception("Streaming DM failed: %s", e)
        try:
            client.chat_postMessage(channel=channel_id, text=f"Received an error from Bolty while streaming:\n{e}")
        except Exception:
            pass


def register(app: App):
    @app.event("message")
    def _on_dm(event, client, logger, say):
        _handle_dm(event, client, logger, say)
