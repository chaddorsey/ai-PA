

**Chad/Spencer check in**
=========================

Time: 2025\-09\-04T13:03:38Z

Transcript:WEBVTT

1

00:00:00\.000 \-\-\> 00:00:02\.120

Chad Dorsey: I've got a record, too, if that's okay.

2

00:00:02\.120 \-\-\> 00:00:03\.610

s: Yeah, that works for me.

3

00:00:04\.170 \-\-\> 00:00:13\.440

Chad Dorsey: Yeah, so, I'm sure you've been busy as well, right? And so, just wanted to give us a chance to check in since, you know, you're doing interesting things,

4

00:00:13\.570 \-\-\> 00:00:24\.469

Chad Dorsey: And, we're doing lots of things at the same time. How's everything going in the first place? Funding is weird these days, so is that affecting you?

5

00:00:25\.150 \-\-\> 00:00:28\.200

s: Yeah, funding has been interesting. So,

6

00:00:28\.370 \-\-\> 00:00:37\.880

s: It has affected me, so, actually, I recently changed labs because, my previous lab,

7

00:00:38\.160 \-\-\> 00:00:41\.390

s: We'll, closed down.

8

00:00:41\.770 \-\-\> 00:00:45\.780

s: because my PI, wanted to retire early because of the…

9

00:00:46\.280 \-\-\> 00:01:03\.320

s: the chaos that's sort of happening. So, he's retired, so I switched to a different lab. So before, I was in Barry Richmond's lab, which was a monkey neurophysiology lab, but now I'm just in a different monkey neurophysiology lab.

10

00:01:03\.320 \-\-\> 00:01:03\.870

Chad Dorsey: Okay.

11

00:01:03\.870 \-\-\> 00:01:15\.819

s: at NIH. So I'm working under Bruno Aberbeck, and I… I've been liking this lab. I think I… I think I like this lab better than my previous lab, so that's good.

12

00:01:16\.470 \-\-\> 00:01:24\.990

s: And… let's see, we're basically, doing,

13

00:01:25\.230 \-\-\> 00:01:39\.450

s: So it's still cognitive neuroscience, so we're interested in behaviors like learning and decision making, and, we basically train them to do some tasks, and then we use, like.

14

00:01:39\.450 \-\-\> 00:01:43\.330

Chad Dorsey: We implant electrodes into the brain, we record…

15

00:01:43\.330 \-\-\> 00:01:54\.949

s: neural activity while the monkey's doing the task. So… that's been interesting, but right now we're just in, like, the training stage. We're just getting the monkey to, like, learn how to do the task.

16

00:01:55\.100 \-\-\> 00:01:59\.399

s: yeah, yeah, yeah. And yep.

17

00:01:59\.400 \-\-\> 00:02:13\.990

Chad Dorsey: What's the length of those, of those, sort of, trial or project runs? I mean, how long is the initial training take? How long is the data analysis, data collection? How long is the analysis? Is this 5 years? 2 years? 2 months?

18

00:02:13\.990 \-\-\> 00:02:18\.229

s: Yeah, it takes forever, let's see, so,

19

00:02:18\.370 \-\-\> 00:02:29\.200

s: Usually training… so I guess it also depends on, like, how good the monkey is at learning the task, but for example, for our task, I think it'll take the monkey about 2 weeks to…

20

00:02:29\.270 \-\-\> 00:02:43\.780

s: be fully trained. Okay. So to, like, because they've been trained on this task before, so it won't take them particularly long. And then after that, we'll start doing recordings, and…

21

00:02:43\.850 \-\-\> 00:02:54\.719

s: I suppose it depends on how many sessions you want, but, right now, the postdoc mentor that I'm working with said about 4 months of

22

00:02:55\.000 \-\-\> 00:03:00\.690

s: like, the monkey just doing the task while recording from their brain.

23

00:03:00\.940 \-\-\> 00:03:09\.479

s: And usually, that's an underestimate, because something usually always goes wrong. Right. So, it'll probably maybe…

24

00:03:10\.160 \-\-\> 00:03:21\.040

s: let's just, like, multiply by 1\.5 and say 6 months, like, half a year or something. And that's just… that's just for one monkey. Usually you want to do at least two. Okay.

25

00:03:21\.040 \-\-\> 00:03:24\.370

Chad Dorsey: So… What sort of hand do you need to be useful?

26

00:03:25\.390 \-\-\> 00:03:38\.929

s: Oh, yeah, right, right. So, oh, so to be useful, I think usually for monkey studies, people usually do two, at least, and that's usually enough to get published.

27

00:03:39\.070 \-\-\> 00:03:42\.599

s: But I guess, ideally, you would want more, but…

28

00:03:42\.790 \-\-\> 00:03:44\.650

Chad Dorsey: Oh, sure, always, but yeah.

29

00:03:44\.650 \-\-\> 00:03:57\.770

s: Yeah, yeah, yeah. But I think it's because of how time\-consuming it is. I think that most of the studies just have two. And yeah. And then for data analysis,

30

00:03:58\.220 \-\-\> 00:04:11\.910

s: I have no idea how long that's going to take. It's… I think it's going to be… I've asked him about the data analysis process, and it seems like that'll be something that'll be happening probably after I leave, because.

31

00:04:12\.300 \-\-\> 00:04:17\.070

s: I'm planning on only staying in this lab for, like, another year.

32

00:04:17\.070 \-\-\> 00:04:17\.709

Chad Dorsey: Huh.

33

00:04:18\.079 \-\-\> 00:04:23\.729

s: And we still need to collect the data on the second monkey as well. So,

34

00:04:24\.589 \-\-\> 00:04:37\.959

s: so we were saying that the analysis is probably something that would be happening afterwards, so I'm not sure, like, how long it'll take, and I've also never analyzed this type of data before, because we're using a different type of recording

35

00:04:37\.959 \-\-\> 00:04:47\.929

s: that, like, has a high throughput of information and data. So we're using, a pro called, NeuroPixels, and,

36

00:04:48\.299 \-\-\> 00:04:57\.129

s: And, I think just because of just, like, the large volume of data, like, for one recording session, it produces 1TB of data.

37

00:04:57\.130 \-\-\> 00:04:57\.510

Chad Dorsey: Wow.

38

00:04:57\.510 \-\-\> 00:05:10\.200

s: And so… and we're gonna have multiple sessions of that. So, it's going to… so it's gonna be interesting. I kind of wish I was there for the data analysis part, but,

39

00:05:12\.530 \-\-\> 00:05:16\.390

s: It is what it is. Yeah, sure. So yeah, yeah.

40

00:05:17\.640 \-\-\> 00:05:24\.180

Chad Dorsey: Interesting. Do you know what you're doing, after that, or what's the… what's the… What was the…

41

00:05:27\.440 \-\-\> 00:05:33\.150

s: So, now I'm going to… I'm going to be applying to graduate school this upcoming cycle.

42

00:05:33\.180 \-\-\> 00:05:48\.669

s: I'm going to be applying to PhD programs and master's programs, and we'll see how all that goes. So hopefully I'll be accepted to a graduate program, but as you already said, funding has been,

43

00:05:48\.670 \-\-\> 00:05:49\.470

Chad Dorsey: Yep.

44

00:05:49\.470 \-\-\> 00:06:05\.979

s: interesting, so it'll make it definitely challenging this cycle, but we'll see, we'll see, we'll see, we'll see. And if I don't need to graduate school, then I'll probably go into just work in industry, I suppose. I'm not sure exactly what I do.

45

00:06:07\.300 \-\-\> 00:06:13\.320

s: I'll probably think about that more in this scenario if I don't get any acceptances.

46

00:06:13\.320 \-\-\> 00:06:13\.950

Chad Dorsey: But…

47

00:06:14\.190 \-\-\> 00:06:16\.530

s: Like, in early next year.

48

00:06:17\.160 \-\-\> 00:06:23\.700

Chad Dorsey: You've got, like, 2 years of lab experience after 3 years? How long have you been working in labs now?

49

00:06:24\.250 \-\-\> 00:06:31\.409

s: So, I think that today actually marks my, like, second year of working at,

50

00:06:31\.530 \-\-\> 00:06:33\.620

s: at the NIH in this lab.

51

00:06:33\.620 \-\-\> 00:06:34\.740

Chad Dorsey: Okay.

52

00:06:34\.950 \-\-\> 00:06:39\.319

s: So… So by the time…

53

00:06:39\.550 \-\-\> 00:06:47\.760

s: I'm… I… but so by the time my fellowship ends next year, it'll be 3 years. Okay. So yeah.

54

00:06:48\.410 \-\-\> 00:06:50\.330

Chad Dorsey: That's… that's solid. Mmm.

55

00:06:50\.770 \-\-\> 00:06:57\.349

s: Yup, yup, yup. So, we'll see, we'll see. But what's… but what about you? What's… what's, happening on your end?

56

00:06:57\.350 \-\-\> 00:07:17\.299

Chad Dorsey: Yeah, I mean, we're, plugging along, doing good stuff as much as we can. You know, we've got lots of, NSF grants in the hopper right now that are, waiting to be approved, which is, usually a good sign, and, you know, still is a good sign, but, the waiting happens more than the approval these days, so we're…

57

00:07:17\.730 \-\-\> 00:07:31\.739

Chad Dorsey: We're sort of, you know, hoping that the timelines work out and that there are enough people around to approve the grants before the clock runs out in the fiscal year at the end of the month, so it's, that's sort of the current, the current process, and then…

58

00:07:31\.740 \-\-\> 00:07:40\.609

Chad Dorsey: You know, there's new, solicitations from NSF out, which we're all still figuring out, right now, and…

59

00:07:40\.800 \-\-\> 00:07:54\.069

Chad Dorsey: they're figuring out how much money is available, depending upon what Congress does or doesn't do in the next, you know, 14 to 20 days, so there's lots of… lots of sort of waiting and figuring out going on on the other side of things.

60

00:07:54\.460 \-\-\> 00:08:07\.589

Chad Dorsey: So, I mean, we're plugging along, continuing our work amid that, thinking broadly about, you know, other kinds of funding sources as need be, also, to, you know, to explore what's possible, and…

61

00:08:07\.640 \-\-\> 00:08:22\.369

Chad Dorsey: trying to understand, you know, sort of best fit in with the sort of new layer of funding. Obviously, AI is, you know, hot in everything, so that's one of the areas that's going to be of interest in funding, regardless of what happens.

62

00:08:22\.880 \-\-\> 00:08:23\.699

s: Okay, yeah.

63

00:08:23\.700 \-\-\> 00:08:28\.070

Chad Dorsey: We've got a number of things that are, you know, sort of Either…

64

00:08:28\.460 \-\-\> 00:08:39\.959

Chad Dorsey: doing education about AI, to help kids learn about AI, and how to use it, and what it means, how it works. And, you know, a number of things that are using AI

65

00:08:40\.150 \-\-\> 00:08:47\.640

Chad Dorsey: tools, processes, techniques in some way for education. So both of those things are… are sort of…

66

00:08:47\.890 \-\-\> 00:08:53\.249

Chad Dorsey: definite areas of interest in the federal funding landscape nowadays, so we're trying to.

67

00:08:53\.250 \-\-\> 00:08:53\.840

s: Oh, okay.

68

00:08:53\.840 \-\-\> 00:08:57\.910

Chad Dorsey: understand how to fit into all of that, I think, is the biggest picture.

69

00:08:59\.200 \-\-\> 00:09:09\.010

s: Yeah, that's interesting. I didn't, realize that there was, I suppose, a stronger push for AI. I guess,

70

00:09:09\.350 \-\-\> 00:09:23\.309

s: And so, for your usages, or, like, for, like, however you're, like, planning on applying AI, is it more so, like, teaching, like, students how to, like, build their own AI systems, or how to…

71

00:09:23\.310 \-\-\> 00:09:32\.460

s: like, leverage AI tools, or, is it more like you're using AI tools to help teach students.

72

00:09:32\.460 \-\-\> 00:09:35\.109

Chad Dorsey: Yeah, it's a combination. So.

73

00:09:35\.110 \-\-\> 00:09:35\.580

s: No.

74

00:09:35\.580 \-\-\> 00:09:43\.080

Chad Dorsey: you know, there's a… there's a set of work that we, are doing under one of our EIs that's,

75

00:09:43\.280 \-\-\> 00:09:44\.819

Chad Dorsey: You know, trying to…

76

00:09:45\.010 \-\-\> 00:09:57\.879

Chad Dorsey: help students understand the processes that, you know, AI tools use to… so, one, you know, can we help you understand what neural nets are and how they, you know, how they work? Can we help you understand how to

77

00:09:57\.940 \-\-\> 00:10:08\.829

Chad Dorsey: You know, build a rudimentary version of something that might be, predictive analysis, etc, etc, so that you can, you know, better understand, you know, the

78

00:10:08\.970 \-\-\> 00:10:18\.680

Chad Dorsey: the algorithms and engines that are underneath AI systems. And then, on the other side, it might be, you know, leveraging

79

00:10:18\.920 \-\-\> 00:10:33\.720

Chad Dorsey: AI to, you know, help, data analysis for blind and low vision users, or using AI algorithms to help suggest, to teachers what the kind of next

80

00:10:33\.820 \-\-\> 00:10:45\.999

Chad Dorsey: teaching moves might be, or to help summarize student work, or things like that, that they can use in real time. So it's a pretty broad variety of possibilities, and broadening as we go, I think.

81

00:10:47\.870 \-\-\> 00:10:49\.089

s: Nice, nice, nice.

82

00:10:49\.200 \-\-\> 00:10:54\.190

s: And that sort of reminds me… so is, also trying to…

83

00:10:54\.390 \-\-\> 00:10:59\.889

s: Make some more progress on the… on, like, the…

84

00:11:00\.190 \-\-\> 00:11:14\.600

s: like, the neuroscience, like, learning platform that we're talking about, in the past. And, I think that sort of reminds me of, of some of the,

85

00:11:15\.210 \-\-\> 00:11:17\.920

s: I guess are some of the things that I've been reading.

86

00:11:18\.080 \-\-\> 00:11:26\.070

s: Because… So… Let's see, let's see, let's see, how do I explain this?

87

00:11:26\.200 \-\-\> 00:11:31\.359

s: So, essentially, the way that I was thinking about maybe, sort of.

88

00:11:31\.530 \-\-\> 00:11:37\.020

s: Designing, like, the learning, like, environment or platform is to…

89

00:11:37\.020 \-\-\> 00:11:56\.990

s: like, sort of essentially simulate, a network of biological neurons connected to each other, which is very reminiscent of neural networks and, like, artificial intelligence. And they're not too dissimilar, and I think, for some of the methods in order to,

90

00:11:57\.450 \-\-\> 00:11:58\.960

s: In order to…

91

00:11:58\.960 \-\-\> 00:12:05\.609

Chad Dorsey: like, fit the parameters, because you don't have all the parameters for, like, a biological neuron. Right, sure.

92

00:12:05\.720 \-\-\> 00:12:19\.379

s: So, a lot of times, like, there's, like, some, like, optimization that could be implemented with, like, an AI in order to identify, like, what parameters, are…

93

00:12:19\.510 \-\-\> 00:12:26\.910

s: Like, best explain, like, the data, or match, like, the neural activity that you're recording.

94

00:12:26\.910 \-\-\> 00:12:27\.980

Chad Dorsey: Right.

95

00:12:28\.260 \-\-\> 00:12:40\.380

s: So yeah, I think that would be interesting. And then that also reminds me that, I haven't looked into this much, but there's also this field called NeuroAI, and

96

00:12:40\.730 \-\-\> 00:12:53\.000

s: I should really read more about it, but I assume it's either, like, AI that's inspired from, like, biological neural systems, or,

97

00:12:53\.840 \-\-\> 00:13:02\.389

s: Or… yeah, yeah, I thought that's probably what it's all about, but I should really look more into it. But that was just, like, another thing that may be interesting.

98

00:13:02\.890 \-\-\> 00:13:10\.149

Chad Dorsey: Yeah, definitely. I think either, either or both, could be, you know, valuable, and, and, you know, for sure it would be interesting.

99

00:13:14\.170 \-\-\> 00:13:19\.909

s: Yeah, so, I mean, as you're… as you're dreaming on that, happy to give, you know.

100

00:13:19\.940 \-\-\> 00:13:24\.900

Chad Dorsey: Feedback, advice, just, you know, look at articles together. If you throw them over the transom via email.

101

00:13:24\.900 \-\-\> 00:13:25\.620

s: Oh, yeah.

102

00:13:25\.620 \-\-\> 00:13:30\.500

Chad Dorsey: Or anything that, you know, comes up, or if you've got datasets that.

103

00:13:30\.760 \-\-\> 00:13:34\.140

Chad Dorsey: are interesting to think about exploring.

104

00:13:34\.380 \-\-\> 00:13:39\.929

Chad Dorsey: You know, that kind of question would be interesting as well, even just thinking about some…

105

00:13:40\.140 \-\-\> 00:13:52\.570

Chad Dorsey: boiled\-down version of the way that you're exploring datasets from the work that you're doing, you know, that students might be able to do would be probably really interesting as well.

106

00:13:53\.080 \-\-\> 00:14:03\.789

s: Okay, sounds nice. Actually, I'll send you two papers that I think I found that would be interesting. Cool. One of them I'm actually going to present in lab meeting next week.

107

00:14:06\.070 \-\-\> 00:14:13\.339

s: It'll… it's, I'll send it to you via email. Yeah. Can you remind me of your email?

108

00:14:13\.350 \-\-\> 00:14:22\.639

Chad Dorsey: Yeah, it's C. Dorsey, C\-D\-O\-R\-S\-E\-Y, at concord.org, C\-O\-N\-C\-O\-R\-D dot org.

109

00:14:23\.890 \-\-\> 00:14:35\.920

s: Okay, nice, nice, nice. So the first paper is called Neurosignification Atlas of C. elegans, and, essentially what this paper… so because the C. elegans is such

110

00:14:35\.930 \-\-\> 00:14:45\.520

s: a simple model organism. It has very few neurons. It has exactly, like, dimension, too. It makes it very easy to,

111

00:14:45\.530 \-\-\> 00:14:53\.680

s: Like, essentially observe all the neurons. Right. And see what they're all doing, and how they're, like, influencing each other.

112

00:14:54\.890 \-\-\> 00:15:08\.160

s: And, also in this paper, they actually used optogenetics to, to, modulate the activity of a single neuron and see how all the other neurons respond to that neuron.

113

00:15:08\.160 \-\-\> 00:15:15\.380

s: like, map for every pair of neurons to see how one reacts to the other. And,

114

00:15:15\.440 \-\-\> 00:15:22\.439

s: it's pretty interesting because they… because we were talking about, because I think that for,

115

00:15:23\.280 \-\-\> 00:15:28\.359

s: for, like, the learning environment, I was imagining is that it would

116

00:15:28\.640 \-\-\> 00:15:33\.560

s: Go a lot into, like, like, basically, like, like, the…

117

00:15:33\.760 \-\-\> 00:15:41\.370

Chad Dorsey: a popular, like, biological motif of, like, structure\-function relationships. Right, and essentially, look at how.

118

00:15:41\.540 \-\-\> 00:15:45\.920

s: Like, the structure of the network,

119

00:15:46\.430 \-\-\> 00:15:50\.959

s: influences, like, its function, essentially. Right.

120

00:15:50\.990 \-\-\> 00:16:01\.059

s: And, I think this would be an interesting paper, because, for C. elegans, you have, like, how every neuron is connected to each other, because it's such a small number of neurons.

121

00:16:01\.060 \-\-\> 00:16:15\.870

s: And in this paper, they're able to record from all the neurons, and then also, change, like, like, like, kick the, kick the, activity into, like, like, modulate its activity up or down.

122

00:16:15\.870 \-\-\> 00:16:21\.459

s: So, there's, like, so they try to make this connection between the structure and function of…

123

00:16:21\.580 \-\-\> 00:16:36\.709

s: of neurons, in this model organism. I think it would also be good for, learning, because it is a small number of neurons. Right. It won't be, like, overwhelming, I suppose. It'll be, like, feel more tractable and maybe also more tangible.

124

00:16:37\.010 \-\-\> 00:16:37\.350

Chad Dorsey: Definitely.

125

00:16:37\.350 \-\-\> 00:16:39\.339

s: students as well.

126

00:16:39\.460 \-\-\> 00:16:42\.070

Chad Dorsey: And, so I'll…

127

00:16:42\.070 \-\-\> 00:16:48\.360

s: Go ahead and, send,

128

00:16:48\.970 \-\-\> 00:16:52\.970

s: that one over. And then the second pivot I was looking at was,

129

00:16:53\.640 \-\-\> 00:17:00\.409

s: So because, essentially, what I want to do is, is make this, like.

130

00:17:00\.660 \-\-\> 00:17:19\.160

s: it's gonna be, like, a digital, like, computational, like, platform or tool. So, I found this paper, where they simulated C. elegant's, like, brain and body, which was kind of interesting. So,

131

00:17:19\.319 \-\-\> 00:17:24\.289

s: I think this would be useful for giving me, like, a starting point for,

132

00:17:25\.569 \-\-\> 00:17:35\.069

s: for… since somebody's already done it, it'll be very nice to just, like, just, like, take the pieces that I need, because I think it'll also have a visual component as well, so… That's…

133

00:17:35\.070 \-\-\> 00:17:35\.420

Chad Dorsey: Awesome.

134

00:17:35\.420 \-\-\> 00:17:42\.690

s: Yeah, so it'll also make visualizing it easier as well. So I wouldn't have to, like, make assets from scratch.

135

00:17:42\.690 \-\-\> 00:17:43\.410

Chad Dorsey: Yeah.

136

00:17:43\.410 \-\-\> 00:17:54\.039

s: And, because… I think it's also good because they also have the body as well, so… That's perfect. You can… Yeah, yeah, yeah, so you can actually see how, like, if you…

137

00:17:54\.490 \-\-\> 00:17:55\.290

s: like…

138

00:17:56\.110 \-\-\> 00:18:04\.829

s: increased activity of this neuron, it makes a warm, like, wiggle a particular way or something, or, like, move forward or move backwards or something.

139

00:18:04\.830 \-\-\> 00:18:05\.230

Chad Dorsey: Yeah.

140

00:18:05\.230 \-\-\> 00:18:15\.529

s: And, I think that'll be also neat for students, because it may… it'll make, like, it feel more tangible, because you can see how, like, different…

141

00:18:15\.640 \-\-\> 00:18:18\.840

s: Neural activity impacts behavior.

142

00:18:19\.110 \-\-\> 00:18:19\.450

Chad Dorsey: Yeah.

143

00:18:20\.450 \-\-\> 00:18:31\.630

s: Yeah, so I'll go ahead and title this, Papers of Interest for Neuro… Learning platform.

144

00:18:34\.890 \-\-\> 00:18:35\.680

s: Okay.

145

00:18:37\.160 \-\-\> 00:18:46\.119

Chad Dorsey: Yeah, that's great. That'd be super cool, Spencer. I think that that's… especially that latter one would be a place to, you know, a huge starting point to… to dig into.

146

00:18:47\.250 \-\-\> 00:18:56\.800

s: Okay, nice, nice, nice. Good to hear, good to hear. Then I'll definitely check out these, because I think last time I was looking into,

147

00:18:57\.880 \-\-\> 00:19:01\.730

s: like, the fly as a model organism. Yep.

148

00:19:02\.060 \-\-\> 00:19:07\.549

s: And, I guess I picked that one because I… I just…

149

00:19:07\.550 \-\-\> 00:19:22\.150

s: we see more, like, exposure to that one, I suppose, because I think that one's, like, the one that's had, I think, the most recent developments, especially in connectomics, but for C. elegans, they've had… they connectome for that model organism for a while now, and.

150

00:19:22\.150 \-\-\> 00:19:22\.990

Chad Dorsey: Right.

151

00:19:23\.350 \-\-\> 00:19:31\.649

s: And I think that it's also neat because it's just so much more attractable, because it's just so much smaller, even though it's bigger.

152

00:19:31\.650 \-\-\> 00:19:32\.900

Chad Dorsey: Totally agree.

153

00:19:32\.900 \-\-\> 00:19:41\.880

s: Yeah, yeah. So, I think that, maybe starting, at least starting with C. elegans would be… would be good,

154

00:19:41\.880 \-\-\> 00:19:42\.460

Chad Dorsey: Yeah.

155

00:19:44\.910 \-\-\> 00:19:46\.569

Chad Dorsey: Yeah, that sounds very cool.

156

00:19:47\.110 \-\-\> 00:19:48\.450

s: Yeah, okay, good, good, good.

157

00:19:50\.320 \-\-\> 00:19:59\.710

s: Yes, no, I definitely need to work on this and figure out how to get it working, but, I think that it would be maybe…

158

00:19:59\.810 \-\-\> 00:20:15\.289

s: useful for me to… if, hmm… maybe I'll just put on my calendar, that, I'm going to intend to set up a meeting with you, maybe?

159

00:20:15\.290 \-\-\> 00:20:15\.660

Chad Dorsey: birth.

160

00:20:15\.660 \-\-\> 00:20:26\.720

s: once a month? Okay. Sure. And so then, I just have, like, a personal, like, deadline to be, like, okay, I need to make sure I work on it so that I have, progress for the next meeting.

161

00:20:26\.720 \-\-\> 00:20:28\.020

Chad Dorsey: Yeah, that sounds awesome.

162

00:20:28\.220 \-\-\> 00:20:33\.120

s: Okay, good, good, good. And then, I'll,

163

00:20:33\.470 \-\-\> 00:20:50\.999

s: reach back out to you, because I know that you're probably busy, so I don't want to schedule time into your… on your calendar if I… if I don't have any updates. But, is… is… is there a certain, like, amount of time I should inform you before we have our meetings? Like, is 2 weeks or one week?

164

00:20:51\.000 \-\-\> 00:20:57\.210

Chad Dorsey: I think, yeah, I think if you… if you mail a couple weeks in advance, then we can find a slot without too much problem, I think.

165

00:20:57\.570 \-\-\> 00:21:06\.969

s: Okay, nice, nice, nice. Okay, nice. So now I'll start thinking about it 2 weeks, kind of in advance. So then I'll probably reach out within 2 weeks,

166

00:21:06\.970 \-\-\> 00:21:07\.520

Chad Dorsey: Sure.

167

00:21:08\.300 \-\-\> 00:21:15\.149

s: So that'll be September 18th. Okay, just making sure I have, like, all the dates so I can,

168

00:21:16\.910 \-\-\> 00:21:19\.770

s: Make sure that it's in my calendar, so that…

169

00:21:19\.770 \-\-\> 00:21:20\.390

Chad Dorsey: Definitely.

170

00:21:20\.390 \-\-\> 00:21:21\.479

s: I don't forget.

171

00:21:24\.920 \-\-\> 00:21:26\.930

s: Okay, nice. Alrighty, thank you, Chad.

172

00:21:26\.930 \-\-\> 00:21:34\.969

Chad Dorsey: Cool! That is awesome, Spencer. I'm glad it worked out, and those sound really fascinating. I'll look forward to digging into the articles a little bit when you have a chance to send them along.

173

00:21:35\.470 \-\-\> 00:21:38\.300

s: Sounds good. Alrighty, you've got it. Thank you, Chad.

174

00:21:38\.300 \-\-\> 00:21:40\.950

Chad Dorsey: Cool, take care, I'll talk to you later, take care.

175

00:21:41\.180 \-\-\> 00:21:42\.680

s: Alrighty, talk to you later. Bye!

176

00:21:42\.680 \-\-\> 00:21:43\.220

Chad Dorsey: Bye.


